# -*- coding: utf-8 -*-
"""Fake_news_generation_and_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l_Nc02KbxXaV-J6GwCT9NGLpmNIKfjVd

# Fake News Generation and Detection (using BERT and GPT)
This project explores the use of GPT for generating realistic fake news articles and BERT for detecting and classifying news as fake or real. By combining text generation and natural language understanding, the project demonstrates how AI can both create and combat misinformation, highlighting the importance of robust fake news detection systems.
"""

#Reinstalls NumPy version 1.26.4, even if it's already installed
!pip install numpy==1.26.4 --force-reinstall

# Importing NumPy and printing the current version
import numpy as np
print("NumPy version:", np.__version__)
# Force-reinstalls and upgrades the key libraries for NLP and deep learning
!pip install --upgrade --force-reinstall transformers datasets torch torchvision

# Importing key libraries and printing their versions to verify installation
import transformers
import torch
print("Transformers version:", transformers.__version__)
print("Torch version:", torch.__version__)

# Essential Libraries
!pip install evaluate

import torch
import pandas as pd
import numpy as np
import random

# Hugging Face Transformers
from transformers import (
    GPT2LMHeadModel,                      # GPT-2 model for text generation
    GPT2Tokenizer,                        # Tokenizer for GPT-2
    BertTokenizer,                        # Tokenizer for BERT
    BertForSequenceClassification,        # BERT model for classification tasks
    Trainer,                              # Trainer class for easy training
    TrainingArguments                     # Configuration for training
)

# Hugging Face Datasets
from datasets import load_dataset          # For loading standard datasets
from evaluate import load as load_metric   # For loading evaluation metrics like accuracy, F1, etc.

# Data Handling
from sklearn.model_selection import train_test_split       # For splitting data into train/test sets

# PyTorch Dataset Handling
from torch.utils.data import Dataset

# Load GPT-2 tokenizer and model for fake news generation
generator_tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
generator_model = GPT2LMHeadModel.from_pretrained("gpt2")
generator_model.eval()

# Function to generate fake news text based on a prompt
def generate_fake_news(prompt, max_length=50):
    inputs = generator_tokenizer.encode(prompt, return_tensors='pt')
    outputs = generator_model.generate(inputs, max_length=max_length, num_return_sequences=1, do_sample=True)
    return generator_tokenizer.decode(outputs[0], skip_special_tokens=True)

# Example
print(generate_fake_news("Breaking: Government announces"))

import requests
import zipfile
import io

# Download dataset zip from UCSB
url = "https://www.cs.ucsb.edu/~william/data/liar_dataset.zip"
response = requests.get(url)
if response.status_code != 200:
    raise Exception(f"Failed to download dataset: HTTP {response.status_code}")

# Extract in-memory
z = zipfile.ZipFile(io.BytesIO(response.content))
z.extractall("/tmp/liar_dataset")
print("✅ Downloaded and extracted LIAR dataset")

import pandas as pd
from sklearn.model_selection import train_test_split

file = "/tmp/liar_dataset/train.tsv"
df = pd.read_csv(file, sep="\t", header=None, quoting=3, on_bad_lines="skip")

df.columns = [
    "id", "label", "statement", "subject", "speaker", "speaker_job_title",
    "state_info", "party_affiliation", "barely_true_counts", "false_counts",
    "half_true_counts", "mostly_true_counts", "pants_on_fire_counts", "context"
]

# Keep only text and label
df = df[['statement', 'label']].dropna().rename(columns={'statement': 'text'})

# Map labels to integers:
label_map = {
    'false': 0, 'pants-fire': 0, 'pants on fire': 0,
    'barely-true': 1,
    'half-true': 2,
    'mostly-true': 3,
    'true': 4
}
df['label'] = df['label'].str.lower().map(label_map).astype(int)

# Split into train and validation
train_texts, val_texts, train_labels, val_labels = train_test_split(
    df['text'], df['label'], test_size=0.2, random_state=42
)

print("✅ Rows loaded:", len(df))
print("  Train:", len(train_texts), "| Validation:", len(val_texts))

bert_tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

train_encodings = bert_tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)
val_encodings = bert_tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)

# Custom Dataset class for PyTorch & Hugging Face Trainer
class FakeNewsDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings    # Tokenized inputs
        self.labels = labels          # Corresponding labels

    def __getitem__(self, idx):
        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} | {"labels": torch.tensor(self.labels[idx])}

    def __len__(self):
        return len(self.labels)

# Wrap tokenized data into PyTorch-compatible datasets
train_dataset = FakeNewsDataset(train_encodings, list(train_labels))
val_dataset = FakeNewsDataset(val_encodings, list(val_labels))

from transformers import BertForSequenceClassification, Trainer, TrainingArguments

# Load pre-trained BERT model for sequence classification with 5 labels
model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=5)

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=2,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    eval_strategy="epoch",
    logging_dir='./logs',
    logging_steps=10,
    report_to="none",
    fp16=True,
)

from torch.utils.data import Subset
train_dataset = Subset(train_dataset, range(500))  # only first 500 samples
val_dataset = Subset(val_dataset, range(100))      # only first 100 samples

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

# Start training!
trainer.train()

def detect_fake_news(text):
    # Tokenize input text for BERT model
    inputs = bert_tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    device = next(model.parameters()).device                 # get device of model (cpu or cuda)
    inputs = {k: v.to(device) for k, v in inputs.items()}    # move inputs to model device
    outputs = model(**inputs)
    logits = outputs.logits                                  # Get predicted class index (0 to 4)
    predicted_class = torch.argmax(logits, dim=1).item()
    return "Fake" if predicted_class == 1 else "Real"

# Generate a fake news headline using GPT-2
headline = generate_fake_news("Breaking: Scientists discover")
print("Generated Headline:", headline)
# Detect if the generated headline is Fake, Real, or Mixed using BERT classifier
print("Detection:", detect_fake_news(headline))

